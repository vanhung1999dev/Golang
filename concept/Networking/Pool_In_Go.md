# ğŸŠâ€â™‚ï¸ What Exactly Is the â€œPoolâ€ in Go's net/http?

- When we say "connection pool" in Go, weâ€™re talking about an in-memory data structure managed by the Go runtime â€” specifically by the http.Transport inside your Go application.
- Itâ€™s not the OS. Itâ€™s not the network layer. Itâ€™s not something external like a database pool.
- **ğŸ‘‰ Itâ€™s purely implemented inside your Go program, as part of the Go standard library.**

## âœ… So, who manages the connection pool?

![](./image/Screenshot_10.png)

The Go http.Transport layer is the one keeping track of: <br>

- Open TCP connections per host
- Which ones are idle
- Which can be reused
- When to close them (IdleConnTimeout)
- How many to keep open (MaxConnsPerHost, etc.)

## ğŸ“¦ Where Is the Pool Stored?

- It lives in memory inside your Go process.
- Each http.Transport instance maintains its own per-host pool:

```
map[string][]*persistConn

```

where persistConn is an internal struct representing a live TCP connection. <br>

## ğŸ’¡ Analogy: Connection Pool in Go vs OS

![](./image/Screenshot_1.png)

## âš™ï¸ Example Lifecycle

Letâ€™s say you hit an API 1000 times/sec: <br>

- ğŸ”Œ First request â†’ Go opens TCP connection via net.Dial
- âœ… Response received â†’ Go keeps connection open
- ğŸ•°ï¸ 2nd request to same host â†’ Go reuses the connection
- ğŸ” After request completes â†’ puts it in pool (idle)
- ğŸ§¹ If idle for too long â†’ closed automatically
- ğŸ”’ If pool is full â†’ Go closes excess idle connections or blocks

All of this logic is inside the Go HTTP client's transport layer, and not visible to the OS beyond actual socket usage. <br>

## ğŸ“ˆ Does It Affect the OS?

Yes â€” indirectly: <br>

- More TCP connections open â†’ more file descriptors used
- Idle connections still consume kernel resources
- Too many can hit OS socket limits (ulimit -n)
- Thatâ€™s why you tune: <br>
  - MaxConnsPerHost
  - IdleConnTimeout
  - and clean up with resp.Body.Close()

## But again: the OS doesnâ€™t manage the pooling â€” your Go app does. <br>

```
Goâ€™s net/http package handles connection pooling automatically using its built-in http.Transport. It's one of the reasons Go's HTTP client is so performant out of the box â€” but it helps to know how it actually works so you can tune it for high-load scenarios.


```

# âš™ï¸ How Connection Pooling Works in net/http

The core of connection pooling lives in: <br>

```
http.DefaultTransport.(*http.Transport)

```

When you use http.Get(), http.Post(), or create a http.Client with default settings, you're using a shared Transport that: <br>

- Reuses TCP connections (keep-alive) across requests to the same host
- Keeps idle connections alive for a configurable time (default: 90s)
- Limits max idle connections per host and in total

```
[http.Client]
     |
     v
[http.Transport]
     |
     |--- Dial â†’ net.Dial or custom Dialer
     |
     |--- Maintains per-host connection pool:
           Host:Port => []*persistConn

```

## âœ… Key Features of the Pool

![](./image/Screenshot_2.png)

## ğŸ› ï¸ Customizing Connection Pool Behavior

```
client := &http.Client{
    Transport: &http.Transport{
        MaxIdleConns:        100,
        MaxIdleConnsPerHost: 10,
        IdleConnTimeout:     30 * time.Second,
        MaxConnsPerHost:     20,
    },
    Timeout: 5 * time.Second, // request timeout
}

```

## ğŸ”¹ Common Tunables:

- MaxIdleConns: Total idle conns across all hosts
- MaxIdleConnsPerHost: Idle connections per host
- MaxConnsPerHost: Total (active + idle) conns per host
- IdleConnTimeout: When to close idle conns
- TLSHandshakeTimeout: How long to wait for TLS setup

## âš ï¸ Gotchas

![](./image/Screenshot_3.png)

## ğŸ’¡ Best Practices

- âœ… Reuse a single http.Client (donâ€™t create one per request)
- âœ… Tune the Transport for your concurrency/load pattern
- âœ… Always close response bodies to release the connection back to the pool
- âœ… Use context.Context or Timeout to avoid hanging requests
- âœ… In long-lived apps, monitor connection metrics

## ğŸ” Real-World Example: High-Load Service

```
var httpClient = &http.Client{
    Transport: &http.Transport{
        MaxIdleConns:        500,
        MaxIdleConnsPerHost: 100,
        MaxConnsPerHost:     200,
        IdleConnTimeout:     90 * time.Second,
    },
    Timeout: 10 * time.Second,
}

```

## ğŸ§  TL;DR

![](./image/Screenshot_4.png)

# ğŸ§  1. Reuses TCP Connections (Keep-Alive)

HTTP/1.1 by default uses persistent connections via the Connection: keep-alive header.
This means instead of opening a new TCP connection for every HTTP request, Go will reuse an existing one if: <br>

- The request is to the same host:port
- The connection is still open and idle
- The server also supports keep-alive (almost all do)

## âœ… Why it matters:

- ğŸ§  Avoids TCP handshake (SYN, ACK, etc.)
- ğŸ” Avoids full TLS handshake (expensive)
- âš¡ï¸ Reduces latency & CPU
- ğŸ’¸ Saves resources on client and server

## ğŸ’¡ In Go:

Go handles this automatically in http.Transport. <br>

```
client := &http.Client{
    Transport: &http.Transport{
        // Keep-alive is on by default
    },
}

```

When you do: <br>

```
resp, _ := client.Get("https://example.com/data")

```

If a connection to example.com:443 is already alive and idle in the pool, it will reuse that TCP connection. <br>

# ğŸ§  2. Keeps Idle Connections Alive (Default: 90s)

## ğŸ” What it is:

- Go does not immediately close a connection after a request finishes.
- It puts the connection back into a per-host idle pool, where it waits for reuse.
- This saves time on future requests, especially for high-throughput or bursty workloads.

## â²ï¸ Default behavior:

```
IdleConnTimeout: 90 * time.Second // default

```

This means: <br>

- If a connection is unused for >90 seconds, it's closed
- If reused within 90s â†’ instant reuse = faster requests

## ğŸ’¡ Customize it:

```
&http.Transport{
    IdleConnTimeout: 30 * time.Second, // shorter lifetime
}

```

âœ… Helps manage resource usage (file descriptors, memory) <br>

## ğŸ§  3. Limits Max Idle Connections (Per Host & Total)

### ğŸ” Why limit?

- Without limits, a high-concurrency system could:
- Leave too many idle connections open
- Exhaust file descriptors (ulimit)
- Create GC pressure or hit OS/network limits

```
&http.Transport{
    MaxIdleConns:        100,  // Total idle connections across all hosts
    MaxIdleConnsPerHost: 10,   // Idle connections allowed per host
    MaxConnsPerHost:     20,   // NEW: max total (idle + active) per host
}

```

- **âš ï¸ If MaxConnsPerHost is reached, further requests to that host are queued until a connection frees up.**

## ğŸ§ª How These Work Together (Example)

```
Transport{
    MaxIdleConns: 100,
    MaxIdleConnsPerHost: 10,
    MaxConnsPerHost: 20,
    IdleConnTimeout: 30 * time.Second,
}

```

Hereâ€™s what happens: <br>

- Up to 20 total connections to any host can be open simultaneously (active or idle)
- Of those, 10 can be kept idle when requests finish
- Any idle conn unused for 30s will be closed
- A new request to the same host:
  - Reuses an idle connection if available
  - Opens a new TCP connection if below 20
  - Otherwise waits until a conn frees up

## âš ï¸ Real-World Impacts

![](./image/Screenshot_5.png)
